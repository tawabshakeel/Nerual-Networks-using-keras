{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Perceptron \n",
    "__1. Most simple Neural Network.__<br>\n",
    "__2. Takes some inputs, sums them up, applies activation function and passes them to output layer.__ <Br>\n",
    "__3. [Towards Data Science Blog BY Andrew Tch for neural networks details ](https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464).__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dowloading_iris():\n",
    "    \"\"\"\n",
    "    Downloading Iris Data from sklear datasets and saving in\n",
    "    datasets folder        \n",
    "    \n",
    "    \"\"\"\n",
    "    iris = load_iris()\n",
    "    ir = pd.DataFrame(iris.data)\n",
    "    ir.columns = iris.feature_names\n",
    "    ir['target'] = iris.target\n",
    "    ir.to_csv('./datasets/iris.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_iris_data():\n",
    "    \"\"\"\n",
    "    Reading iris datasets and separting target and features\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('./datasets/iris.csv')\n",
    "    \n",
    "    X = df.iloc[:,0:4].values\n",
    "    y = df.iloc[:,4].values\n",
    "    \n",
    "    return X,y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_data():\n",
    "    \"\"\"\n",
    "    Splitting datasets into train and test sets\n",
    "    \"\"\"\n",
    "    X,y = reading_iris_data()\n",
    "    y = to_categorical(y)\n",
    "    X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    return X_train,X_test, y_train,y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_model():\n",
    "    \"\"\"\n",
    "    Initializing Model creating Perceptron\n",
    "    \"\"\"\n",
    "    X_train,X_test, y_train,y_test = splitting_data()\n",
    "    # Initialising the ANN\n",
    "    classifier = Sequential()\n",
    "    # Adding the Single Perceptron \n",
    "    classifier.add(Dense(32,activation='relu', input_dim=4))\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # criterion loss and optimizer \n",
    "    classifier.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "    classifier.fit(X_train, y_train, batch_size=100, nb_epoch=150)\n",
    "    y_pred = classifier.predict_classes(X_test)\n",
    "    return y_test,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tawab shakeel\\anaconda2\\envs\\machinelearning\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 1.5507 - acc: 0.3083\n",
      "Epoch 2/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 1.4988 - acc: 0.3083\n",
      "Epoch 3/150\n",
      "120/120 [==============================] - 0s 133us/step - loss: 1.4507 - acc: 0.3417\n",
      "Epoch 4/150\n",
      "120/120 [==============================] - 0s 137us/step - loss: 1.4080 - acc: 0.3750\n",
      "Epoch 5/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 1.3660 - acc: 0.4583\n",
      "Epoch 6/150\n",
      "120/120 [==============================] - 0s 179us/step - loss: 1.3297 - acc: 0.5167\n",
      "Epoch 7/150\n",
      "120/120 [==============================] - 0s 87us/step - loss: 1.2974 - acc: 0.5500\n",
      "Epoch 8/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 1.2694 - acc: 0.5250\n",
      "Epoch 9/150\n",
      "120/120 [==============================] - 0s 100us/step - loss: 1.2451 - acc: 0.5167\n",
      "Epoch 10/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 1.2228 - acc: 0.4917\n",
      "Epoch 11/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 1.2020 - acc: 0.4500\n",
      "Epoch 12/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 1.1816 - acc: 0.4167\n",
      "Epoch 13/150\n",
      "120/120 [==============================] - 0s 104us/step - loss: 1.1639 - acc: 0.4083\n",
      "Epoch 14/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 1.1471 - acc: 0.3917\n",
      "Epoch 15/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 1.1309 - acc: 0.3917\n",
      "Epoch 16/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 1.1142 - acc: 0.3917\n",
      "Epoch 17/150\n",
      "120/120 [==============================] - 0s 75us/step - loss: 1.0985 - acc: 0.3917\n",
      "Epoch 18/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 1.0834 - acc: 0.3917\n",
      "Epoch 19/150\n",
      "120/120 [==============================] - 0s 91us/step - loss: 1.0685 - acc: 0.4083\n",
      "Epoch 20/150\n",
      "120/120 [==============================] - 0s 112us/step - loss: 1.0553 - acc: 0.4250\n",
      "Epoch 21/150\n",
      "120/120 [==============================] - 0s 220us/step - loss: 1.0412 - acc: 0.4417\n",
      "Epoch 22/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 1.0295 - acc: 0.4583\n",
      "Epoch 23/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 1.0170 - acc: 0.4917\n",
      "Epoch 24/150\n",
      "120/120 [==============================] - 0s 79us/step - loss: 1.0056 - acc: 0.4917\n",
      "Epoch 25/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.9936 - acc: 0.5000\n",
      "Epoch 26/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.9819 - acc: 0.5167\n",
      "Epoch 27/150\n",
      "120/120 [==============================] - 0s 91us/step - loss: 0.9706 - acc: 0.5000\n",
      "Epoch 28/150\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.9589 - acc: 0.5083\n",
      "Epoch 29/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.9478 - acc: 0.5167\n",
      "Epoch 30/150\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.9368 - acc: 0.5167\n",
      "Epoch 31/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.9263 - acc: 0.5083\n",
      "Epoch 32/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.9165 - acc: 0.5000\n",
      "Epoch 33/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.9066 - acc: 0.5083\n",
      "Epoch 34/150\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.8986 - acc: 0.5000\n",
      "Epoch 35/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.8903 - acc: 0.5000\n",
      "Epoch 36/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.8827 - acc: 0.5000\n",
      "Epoch 37/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.8756 - acc: 0.5000\n",
      "Epoch 38/150\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.8689 - acc: 0.5000\n",
      "Epoch 39/150\n",
      "120/120 [==============================] - 0s 96us/step - loss: 0.8621 - acc: 0.5000\n",
      "Epoch 40/150\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.8552 - acc: 0.5000\n",
      "Epoch 41/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.8487 - acc: 0.5000\n",
      "Epoch 42/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.8417 - acc: 0.5000\n",
      "Epoch 43/150\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.8354 - acc: 0.4917\n",
      "Epoch 44/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.8290 - acc: 0.4667\n",
      "Epoch 45/150\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.8229 - acc: 0.4583\n",
      "Epoch 46/150\n",
      "120/120 [==============================] - 0s 146us/step - loss: 0.8170 - acc: 0.4500\n",
      "Epoch 47/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.8110 - acc: 0.4500\n",
      "Epoch 48/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.8050 - acc: 0.4500\n",
      "Epoch 49/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.7991 - acc: 0.4500\n",
      "Epoch 50/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.7937 - acc: 0.4917\n",
      "Epoch 51/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.7881 - acc: 0.5917\n",
      "Epoch 52/150\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.7829 - acc: 0.7167\n",
      "Epoch 53/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.7774 - acc: 0.7583\n",
      "Epoch 54/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.7722 - acc: 0.8000\n",
      "Epoch 55/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.7672 - acc: 0.8167\n",
      "Epoch 56/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.7624 - acc: 0.8250\n",
      "Epoch 57/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.7572 - acc: 0.8250\n",
      "Epoch 58/150\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.7524 - acc: 0.8250\n",
      "Epoch 59/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.7478 - acc: 0.8250\n",
      "Epoch 60/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.7433 - acc: 0.8333\n",
      "Epoch 61/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.7385 - acc: 0.8333\n",
      "Epoch 62/150\n",
      "120/120 [==============================] - 0s 75us/step - loss: 0.7340 - acc: 0.8333\n",
      "Epoch 63/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.7292 - acc: 0.8333\n",
      "Epoch 64/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.7247 - acc: 0.8333\n",
      "Epoch 65/150\n",
      "120/120 [==============================] - 0s 42us/step - loss: 0.7200 - acc: 0.8333\n",
      "Epoch 66/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.7155 - acc: 0.8250\n",
      "Epoch 67/150\n",
      "120/120 [==============================] - 0s 233us/step - loss: 0.7110 - acc: 0.8250\n",
      "Epoch 68/150\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.7065 - acc: 0.8250\n",
      "Epoch 69/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.7021 - acc: 0.8250\n",
      "Epoch 70/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.6977 - acc: 0.8250\n",
      "Epoch 71/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.6937 - acc: 0.8250\n",
      "Epoch 72/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6890 - acc: 0.8250\n",
      "Epoch 73/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6846 - acc: 0.8250\n",
      "Epoch 74/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6798 - acc: 0.8250\n",
      "Epoch 75/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.6756 - acc: 0.8250\n",
      "Epoch 76/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.6712 - acc: 0.8333\n",
      "Epoch 77/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6668 - acc: 0.8333\n",
      "Epoch 78/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.6625 - acc: 0.8333\n",
      "Epoch 79/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.6581 - acc: 0.8333\n",
      "Epoch 80/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.6540 - acc: 0.8333\n",
      "Epoch 81/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6496 - acc: 0.8417\n",
      "Epoch 82/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.6453 - acc: 0.8417\n",
      "Epoch 83/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.6409 - acc: 0.8417\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 54us/step - loss: 0.6367 - acc: 0.8333\n",
      "Epoch 85/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.6325 - acc: 0.8333\n",
      "Epoch 86/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.6285 - acc: 0.8333\n",
      "Epoch 87/150\n",
      "120/120 [==============================] - 0s 100us/step - loss: 0.6243 - acc: 0.8333\n",
      "Epoch 88/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.6207 - acc: 0.8250\n",
      "Epoch 89/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.6167 - acc: 0.8250\n",
      "Epoch 90/150\n",
      "120/120 [==============================] - 0s 125us/step - loss: 0.6127 - acc: 0.8250\n",
      "Epoch 91/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6085 - acc: 0.8333\n",
      "Epoch 92/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.6045 - acc: 0.8333\n",
      "Epoch 93/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.6006 - acc: 0.8333\n",
      "Epoch 94/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5968 - acc: 0.8333\n",
      "Epoch 95/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5930 - acc: 0.8333\n",
      "Epoch 96/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.5890 - acc: 0.8333\n",
      "Epoch 97/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.5853 - acc: 0.8333\n",
      "Epoch 98/150\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.5818 - acc: 0.8583\n",
      "Epoch 99/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5779 - acc: 0.8667\n",
      "Epoch 100/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.5743 - acc: 0.8667\n",
      "Epoch 101/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.5707 - acc: 0.8667\n",
      "Epoch 102/150\n",
      "120/120 [==============================] - 0s 112us/step - loss: 0.5670 - acc: 0.8667\n",
      "Epoch 103/150\n",
      "120/120 [==============================] - 0s 46us/step - loss: 0.5633 - acc: 0.8500\n",
      "Epoch 104/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5600 - acc: 0.8333\n",
      "Epoch 105/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5569 - acc: 0.8333\n",
      "Epoch 106/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5539 - acc: 0.8333\n",
      "Epoch 107/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5507 - acc: 0.8333\n",
      "Epoch 108/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.5475 - acc: 0.8333\n",
      "Epoch 109/150\n",
      "120/120 [==============================] - 0s 46us/step - loss: 0.5439 - acc: 0.8333\n",
      "Epoch 110/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5403 - acc: 0.8333\n",
      "Epoch 111/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5366 - acc: 0.8417\n",
      "Epoch 112/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5333 - acc: 0.8750\n",
      "Epoch 113/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5306 - acc: 0.8917\n",
      "Epoch 114/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5277 - acc: 0.9000\n",
      "Epoch 115/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5250 - acc: 0.9167\n",
      "Epoch 116/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.5223 - acc: 0.9167\n",
      "Epoch 117/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.5191 - acc: 0.9167\n",
      "Epoch 118/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.5159 - acc: 0.9167\n",
      "Epoch 119/150\n",
      "120/120 [==============================] - 0s 71us/step - loss: 0.5124 - acc: 0.9167\n",
      "Epoch 120/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.5093 - acc: 0.9083\n",
      "Epoch 121/150\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.5062 - acc: 0.9083\n",
      "Epoch 122/150\n",
      "120/120 [==============================] - 0s 108us/step - loss: 0.5031 - acc: 0.9000\n",
      "Epoch 123/150\n",
      "120/120 [==============================] - 0s 83us/step - loss: 0.5000 - acc: 0.8917\n",
      "Epoch 124/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.4973 - acc: 0.8917\n",
      "Epoch 125/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.4943 - acc: 0.8917\n",
      "Epoch 126/150\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.4915 - acc: 0.8833\n",
      "Epoch 127/150\n",
      "120/120 [==============================] - 0s 92us/step - loss: 0.4888 - acc: 0.8833\n",
      "Epoch 128/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.4861 - acc: 0.8833\n",
      "Epoch 129/150\n",
      "120/120 [==============================] - 0s 183us/step - loss: 0.4834 - acc: 0.8833\n",
      "Epoch 130/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.4807 - acc: 0.8833\n",
      "Epoch 131/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.4781 - acc: 0.8917\n",
      "Epoch 132/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.4755 - acc: 0.8917\n",
      "Epoch 133/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4728 - acc: 0.8917\n",
      "Epoch 134/150\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.4703 - acc: 0.9083\n",
      "Epoch 135/150\n",
      "120/120 [==============================] - 0s 104us/step - loss: 0.4678 - acc: 0.9083\n",
      "Epoch 136/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.4653 - acc: 0.9167\n",
      "Epoch 137/150\n",
      "120/120 [==============================] - 0s 87us/step - loss: 0.4632 - acc: 0.9167\n",
      "Epoch 138/150\n",
      "120/120 [==============================] - 0s 46us/step - loss: 0.4611 - acc: 0.9417\n",
      "Epoch 139/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4594 - acc: 0.9333\n",
      "Epoch 140/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.4569 - acc: 0.9333\n",
      "Epoch 141/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.4541 - acc: 0.9417\n",
      "Epoch 142/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.4514 - acc: 0.9333\n",
      "Epoch 143/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.4487 - acc: 0.9167\n",
      "Epoch 144/150\n",
      "120/120 [==============================] - 0s 79us/step - loss: 0.4461 - acc: 0.9167\n",
      "Epoch 145/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4440 - acc: 0.9167\n",
      "Epoch 146/150\n",
      "120/120 [==============================] - 0s 58us/step - loss: 0.4422 - acc: 0.9000\n",
      "Epoch 147/150\n",
      "120/120 [==============================] - 0s 67us/step - loss: 0.4400 - acc: 0.8917\n",
      "Epoch 148/150\n",
      "120/120 [==============================] - 0s 50us/step - loss: 0.4379 - acc: 0.8917\n",
      "Epoch 149/150\n",
      "120/120 [==============================] - 0s 62us/step - loss: 0.4359 - acc: 0.8917\n",
      "Epoch 150/150\n",
      "120/120 [==============================] - 0s 54us/step - loss: 0.4340 - acc: 0.8917\n"
     ]
    }
   ],
   "source": [
    "y_test,y_pred = perceptron_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = multilabel_confusion_matrix(y_test, to_categorical(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[19,  0],\n",
       "        [ 0, 11]],\n",
       "\n",
       "       [[17,  0],\n",
       "        [ 4,  9]],\n",
       "\n",
       "       [[20,  4],\n",
       "        [ 0,  6]]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
